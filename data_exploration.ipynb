{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed23305b",
   "metadata": {},
   "source": [
    "# Health Insurance Cross-Sell Prediction: Data Exploration & Modeling\n",
    "\n",
    "This notebook walks through a complete workflow for predicting customer interest in health insurance cross-sell using machine learning. The steps include:\n",
    "\n",
    "- **Data Loading & Cleaning**: Import and inspect the data, handle missing values, and ensure correct data types.\n",
    "- **Exploratory Data Analysis (EDA)**: Visualize distributions, check for outliers, and understand feature relationships.\n",
    "- **Feature Engineering**: Encode categorical variables, scale features, and prepare data for modeling.\n",
    "- **Model Training & Evaluation**: Train several classifiers (Logistic Regression, Random Forest, XGBoost, LightGBM, CatBoost), balance the data, and compare performance.\n",
    "- **Summary & Next Steps**: Summarize findings, results, and suggest improvements.\n",
    "\n",
    "Best practices such as reproducibility, clear documentation, and robust evaluation are followed throughout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0372352a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Data Loading & Setup ---\n",
    "# Import required libraries for data handling, visualization, and modeling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# For model building and evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "# For handling imbalanced data\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# For models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933d08f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data\n",
    "df = pd.read_csv('./data/train.csv')\n",
    "\n",
    "# Show the first 5 rows to inspect the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6c9a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Removed: duplicate df.head() call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98344c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dataset Features Overview\n",
    "\n",
    "# - **id**: Customer ID (unique identifier)\n",
    "# - **Gender**: Male/Female\n",
    "# - **Age**: Customer age (numeric)\n",
    "# - **Driving_License**: 1 if customer has a driving license, else 0\n",
    "# - **Previously_Insured**: 1 if already has health insurance, else 0\n",
    "# - **Vehicle_Age**: Age of the vehicle ('< 1 Year', '1-2 Year', '> 2 Years')\n",
    "# - **Vehicle_Damage**: Was vehicle previously damaged? (Yes/No)\n",
    "# - **Annual_Premium**: Yearly insurance premium (numeric)\n",
    "# - **Policy_Sales_Channel**: Channel through which policy was sold (numeric code)\n",
    "# - **Vintage**: Days since customer joined\n",
    "# - **Response**: Target variable (0 = not interested, 1 = interested)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a249f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show info, summary statistics, and missing values\n",
    "display(df.info())\n",
    "display(df.describe())\n",
    "display(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b8dd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e5856f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d23236b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distributions for numeric and categorical features\n",
    "numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Plot numeric features\n",
    "df[numeric_cols].hist(figsize=(14, 10), bins=30, layout=(3, 4))\n",
    "plt.suptitle('Numeric Feature Distributions')\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()\n",
    "\n",
    "# Plot categorical features\n",
    "for col in categorical_cols:\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.countplot(x=col, data=df)\n",
    "    plt.title(f'Distribution of {col}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073d0138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of the target variable\n",
    "sns.countplot(x='Response', data=df)\n",
    "plt.title('Response Distribution (Target Variable)')\n",
    "plt.xlabel('Response')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1bd3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplots for numeric features to check for outliers\n",
    "for col in numeric_cols:\n",
    "    plt.figure(figsize=(8, 2))\n",
    "    sns.boxplot(x=df[col])\n",
    "    plt.title(f'Boxplot of {col}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73382f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers from Annual_Premium using IQR\n",
    "q1 = df['Annual_Premium'].quantile(0.25)\n",
    "q3 = df['Annual_Premium'].quantile(0.75)\n",
    "iqr = q3 - q1\n",
    "lower_bound = q1 - 1.5 * iqr\n",
    "upper_bound = q3 + 1.5 * iqr\n",
    "df = df[(df['Annual_Premium'] >= lower_bound) & (df['Annual_Premium'] <= upper_bound)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b12020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log transform Annual_Premium to reduce skewness\n",
    "df['Annual_Premium_log'] = np.log1p(df['Annual_Premium'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e634fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define categorical and numerical features\n",
    "categorical = ['Vehicle_Damage', 'Previously_Insured', 'Vehicle_Age']\n",
    "numerical = ['Policy_Sales_Channel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b6704e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value counts for categorical features\n",
    "for col in categorical:\n",
    "    print(f\"Value counts for {col}:\")\n",
    "    print(df[col].value_counts())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cabfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value counts for numerical features\n",
    "for col in numerical:\n",
    "    print(f\"Value counts for {col}:\")\n",
    "    print(df[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a6960c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix for numerical features\n",
    "correlation_matrix = df.corr()\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Correlation Matrix of Numerical Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3625bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea45785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the categorical and numerical features\n",
    "\n",
    "categorical = ['Vehicle_Damage' , 'Previously_Insured', 'Vehicle_Age']\n",
    "\n",
    "numerical = ['Policy_Sales_Channel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574c51bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical features\n",
    "vehicle_age_map = {\n",
    "    \"1-2 Year\": 0,\n",
    "    \"< 1 Year\": 1,\n",
    "    \"> 2 Years\": 2\n",
    "}\n",
    "df[\"Vehicle_Age\"] = df[\"Vehicle_Age\"].map(vehicle_age_map)\n",
    "\n",
    "le = LabelEncoder()\n",
    "for col in df.select_dtypes(include=['object']).columns:\n",
    "    if col != 'Vehicle_Age':\n",
    "        df[col] = le.fit_transform(df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79fa223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize numerical features (excluding target and categorical)\n",
    "scaler = StandardScaler()\n",
    "for col in df.select_dtypes(include=['int64', 'float64']).columns:\n",
    "    if col != 'Response' and col not in categorical and col != 'Vehicle_Age':\n",
    "        df[col] = scaler.fit_transform(df[[col]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbf8880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the cleaned dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b060f545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target\n",
    "X = df.drop(['Response', 'id'], axis=1)\n",
    "y = df['Response']\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Handle class imbalance with SMOTE (oversampling) and random undersampling\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_train_balanced, y_train_balanced = rus.fit_resample(X_train_res, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c1c61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to train and evaluate models\n",
    "def train_and_evaluate(model, X_train, y_train, X_test, y_test, model_name):\n",
    "    \"\"\"Train the model and print evaluation metrics.\"\"\"\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"\\n--- {model_name} ---\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"ROC AUC Score:\", roc_auc_score(y_test, y_pred))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# List of models to evaluate\n",
    "models = [\n",
    "    (LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42), 'Logistic Regression'),\n",
    "    (RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42), 'Random Forest'),\n",
    "    (XGBClassifier(eval_metric='logloss', scale_pos_weight=1, use_label_encoder=False, random_state=42), 'XGBoost'),\n",
    "    (LGBMClassifier(class_weight='balanced', random_state=42), 'LightGBM'),\n",
    "    (CatBoostClassifier(verbose=0, random_state=42), 'CatBoost')\n",
    "]\n",
    "\n",
    "# Train and evaluate each model\n",
    "for model, name in models:\n",
    "    train_and_evaluate(model, X_train_balanced, y_train_balanced, X_test, y_test, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ef016b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Removed: XGBoost cell, now handled in unified model evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854036c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use LightGBM or CatBoost \n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "lgbm = LGBMClassifier(class_weight='balanced')\n",
    "lgbm.fit(X_train_balanced, y_train_balanced)\n",
    "y_pred = lgbm.predict(X_test)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"ROC AUC Score:\", roc_auc_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "#  --- IGNORE ---\n",
    "#  --- IGNORE ---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7102dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "catboost = CatBoostClassifier(verbose=0)\n",
    "catboost.fit(X_train_balanced, y_train_balanced)\n",
    "y_pred = catboost.predict(X_test)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"ROC AUC Score:\", roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f665036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insurance Health Cross-Sell Prediction - Optimized with MLflow\n",
    "# =================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import logging\n",
    "from typing import Tuple, Dict, Any, List\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "import time\n",
    "\n",
    "# ML Libraries\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import (accuracy_score, classification_report, confusion_matrix, \n",
    "                           roc_auc_score, precision_recall_curve, roc_curve, f1_score)\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# MLflow\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.xgboost\n",
    "import mlflow.lightgbm\n",
    "import mlflow.catboost\n",
    "\n",
    "# Configuration\n",
    "warnings.filterwarnings('ignore')\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Constants\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "# MLflow Configuration\n",
    "EXPERIMENT_NAME = \"insurance-cross-sell-prediction\"\n",
    "TRACKING_URI = \"sqlite:///mlflow.db\"  # Local SQLite database\n",
    "# For remote server: TRACKING_URI = \"http://your-mlflow-server:5000\"\n",
    "\n",
    "# =================================================================\n",
    "# 1. CONFIGURATION AND SETUP\n",
    "# =================================================================\n",
    "\n",
    "class Config:\n",
    "    \"\"\"Configuration class for the ML pipeline\"\"\"\n",
    "    RANDOM_STATE = 42\n",
    "    TEST_SIZE = 0.2\n",
    "    CV_FOLDS = 5\n",
    "    DATA_PATH = './data/train.csv'\n",
    "    MODEL_SAVE_PATH = './models/'\n",
    "    \n",
    "    # Outlier removal parameters\n",
    "    OUTLIER_METHOD = 'iqr'\n",
    "    IQR_FACTOR = 1.5\n",
    "\n",
    "def setup_mlflow():\n",
    "    \"\"\"Setup MLflow tracking\"\"\"\n",
    "    mlflow.set_tracking_uri(TRACKING_URI)\n",
    "    \n",
    "    # Create experiment if it doesn't exist\n",
    "    try:\n",
    "        experiment_id = mlflow.create_experiment(EXPERIMENT_NAME)\n",
    "    except mlflow.exceptions.MlflowException:\n",
    "        experiment = mlflow.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "        experiment_id = experiment.experiment_id\n",
    "    \n",
    "    mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "    logger.info(f\"MLflow experiment '{EXPERIMENT_NAME}' set up successfully\")\n",
    "    return experiment_id\n",
    "\n",
    "# =================================================================\n",
    "# 2. DATA LOADING AND PREPROCESSING\n",
    "# =================================================================\n",
    "\n",
    "class DataLoader:\n",
    "    \"\"\"Data loading and basic validation\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def load_data(file_path: str) -> pd.DataFrame:\n",
    "        \"\"\"Load data with basic validation\"\"\"\n",
    "        start_time = time.time()\n",
    "        \n",
    "        if not Path(file_path).exists():\n",
    "            raise FileNotFoundError(f\"Data file not found: {file_path}\")\n",
    "        \n",
    "        df = pd.read_csv(file_path)\n",
    "        load_time = time.time() - start_time\n",
    "        \n",
    "        logger.info(f\"Data loaded successfully in {load_time:.2f} seconds\")\n",
    "        logger.info(f\"Dataset shape: {df.shape}\")\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    @staticmethod\n",
    "    def basic_data_info(df: pd.DataFrame) -> Dict[str, Any]:\n",
    "        \"\"\"Get basic information about the dataset\"\"\"\n",
    "        info = {\n",
    "            'shape': df.shape,\n",
    "            'memory_usage_mb': df.memory_usage(deep=True).sum() / 1024**2,\n",
    "            'missing_values': df.isnull().sum().to_dict(),\n",
    "            'dtypes': df.dtypes.to_dict(),\n",
    "            'target_distribution': df['Response'].value_counts().to_dict() if 'Response' in df.columns else None\n",
    "        }\n",
    "        return info\n",
    "\n",
    "class DataPreprocessor:\n",
    "    \"\"\"Comprehensive data preprocessing pipeline\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.scalers = {}\n",
    "        self.encoders = {}\n",
    "        self.feature_names = []\n",
    "        \n",
    "    def remove_outliers(self, df: pd.DataFrame, column: str, method: str = 'iqr', factor: float = 1.5) -> pd.DataFrame:\n",
    "        \"\"\"Remove outliers using IQR method\"\"\"\n",
    "        if method == 'iqr':\n",
    "            q1 = df[column].quantile(0.25)\n",
    "            q3 = df[column].quantile(0.75)\n",
    "            iqr = q3 - q1\n",
    "            lower_bound = q1 - factor * iqr\n",
    "            upper_bound = q3 + factor * iqr\n",
    "            \n",
    "            outliers_count = len(df[(df[column] < lower_bound) | (df[column] > upper_bound)])\n",
    "            df_cleaned = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "            \n",
    "            logger.info(f\"Removed {outliers_count} outliers from {column}\")\n",
    "            return df_cleaned\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported outlier removal method: {method}\")\n",
    "    \n",
    "    def engineer_features(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Feature engineering pipeline\"\"\"\n",
    "        df = df.copy()\n",
    "        \n",
    "        # Log transform for Annual_Premium\n",
    "        df['Annual_Premium_log'] = np.log1p(df['Annual_Premium'])\n",
    "        \n",
    "        # Age groups\n",
    "        df['Age_Group'] = pd.cut(df['Age'], bins=[0, 25, 35, 50, 100], \n",
    "                                labels=['Young', 'Adult', 'Middle_Age', 'Senior'])\n",
    "        \n",
    "        # Premium per age ratio\n",
    "        df['Premium_Age_Ratio'] = df['Annual_Premium'] / df['Age']\n",
    "        \n",
    "        # Vehicle age mapping\n",
    "        vehicle_age_map = {\n",
    "            '< 1 Year': 0,\n",
    "            '1-2 Year': 1,\n",
    "            '> 2 Years': 2\n",
    "        }\n",
    "        df['Vehicle_Age_Numeric'] = df['Vehicle_Age'].map(vehicle_age_map)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def encode_categorical(self, df: pd.DataFrame, fit: bool = True) -> pd.DataFrame:\n",
    "        \"\"\"Encode categorical variables\"\"\"\n",
    "        df = df.copy()\n",
    "        categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "        \n",
    "        # Remove target if present\n",
    "        if 'Response' in categorical_cols:\n",
    "            categorical_cols.remove('Response')\n",
    "        \n",
    "        for col in categorical_cols:\n",
    "            if fit:\n",
    "                if col not in self.encoders:\n",
    "                    self.encoders[col] = LabelEncoder()\n",
    "                df[col] = self.encoders[col].fit_transform(df[col])\n",
    "            else:\n",
    "                if col in self.encoders:\n",
    "                    df[col] = self.encoders[col].transform(df[col])\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def scale_features(self, df: pd.DataFrame, fit: bool = True) -> pd.DataFrame:\n",
    "        \"\"\"Scale numerical features\"\"\"\n",
    "        df = df.copy()\n",
    "        \n",
    "        # Identify numerical columns to scale\n",
    "        numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "        categorical_indicators = ['Vehicle_Damage', 'Previously_Insured', 'Vehicle_Age_Numeric']\n",
    "        \n",
    "        # Remove target, ID, and categorical indicators\n",
    "        cols_to_exclude = ['Response', 'id'] + categorical_indicators\n",
    "        numerical_cols = [col for col in numerical_cols if col not in cols_to_exclude]\n",
    "        \n",
    "        for col in numerical_cols:\n",
    "            if fit:\n",
    "                if col not in self.scalers:\n",
    "                    self.scalers[col] = StandardScaler()\n",
    "                df[col] = self.scalers[col].fit_transform(df[[col]]).flatten()\n",
    "            else:\n",
    "                if col in self.scalers:\n",
    "                    df[col] = self.scalers[col].transform(df[[col]]).flatten()\n",
    "        \n",
    "        self.feature_names = df.columns.tolist()\n",
    "        return df\n",
    "    \n",
    "    def fit_transform(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Complete preprocessing pipeline\"\"\"\n",
    "        logger.info(\"Starting data preprocessing...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Remove outliers\n",
    "        df = self.remove_outliers(df, 'Annual_Premium')\n",
    "        \n",
    "        # Feature engineering\n",
    "        df = self.engineer_features(df)\n",
    "        \n",
    "        # Encode categorical variables\n",
    "        df = self.encode_categorical(df, fit=True)\n",
    "        \n",
    "        # Scale numerical features\n",
    "        df = self.scale_features(df, fit=True)\n",
    "        \n",
    "        preprocessing_time = time.time() - start_time\n",
    "        logger.info(f\"Preprocessing completed in {preprocessing_time:.2f} seconds\")\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def transform(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Transform new data using fitted preprocessors\"\"\"\n",
    "        df = self.engineer_features(df)\n",
    "        df = self.encode_categorical(df, fit=False)\n",
    "        df = self.scale_features(df, fit=False)\n",
    "        return df\n",
    "\n",
    "# =================================================================\n",
    "# 3. DATA EXPLORATION AND VISUALIZATION\n",
    "# =================================================================\n",
    "\n",
    "class DataExplorer:\n",
    "    \"\"\"Data exploration and visualization utilities\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def plot_distributions(df: pd.DataFrame, figsize: Tuple[int, int] = (15, 10)):\n",
    "        \"\"\"Plot distributions of numerical features\"\"\"\n",
    "        numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "        if 'Response' in numeric_cols:\n",
    "            numeric_cols.remove('Response')\n",
    "        \n",
    "        n_cols = len(numeric_cols)\n",
    "        n_rows = (n_cols // 4) + (1 if n_cols % 4 else 0)\n",
    "        \n",
    "        fig, axes = plt.subplots(n_rows, 4, figsize=figsize)\n",
    "        axes = axes.flatten() if n_rows > 1 else [axes]\n",
    "        \n",
    "        for i, col in enumerate(numeric_cols):\n",
    "            if i < len(axes):\n",
    "                df[col].hist(bins=30, ax=axes[i])\n",
    "                axes[i].set_title(col)\n",
    "                axes[i].set_xlabel(col)\n",
    "                axes[i].set_ylabel('Frequency')\n",
    "        \n",
    "        # Hide unused subplots\n",
    "        for i in range(len(numeric_cols), len(axes)):\n",
    "            axes[i].set_visible(False)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    @staticmethod\n",
    "    def plot_correlation_matrix(df: pd.DataFrame, figsize: Tuple[int, int] = (12, 10)):\n",
    "        \"\"\"Plot correlation matrix\"\"\"\n",
    "        numeric_df = df.select_dtypes(include=['int64', 'float64'])\n",
    "        correlation_matrix = numeric_df.corr()\n",
    "        \n",
    "        plt.figure(figsize=figsize)\n",
    "        sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', \n",
    "                   square=True, linewidths=0.5)\n",
    "        plt.title('Feature Correlation Matrix')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    @staticmethod\n",
    "    def plot_target_distribution(df: pd.DataFrame):\n",
    "        \"\"\"Plot target variable distribution\"\"\"\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        target_counts = df['Response'].value_counts()\n",
    "        \n",
    "        sns.countplot(data=df, x='Response')\n",
    "        plt.title('Target Variable Distribution')\n",
    "        \n",
    "        # Add percentage labels\n",
    "        total = len(df)\n",
    "        for i, v in enumerate(target_counts.values):\n",
    "            plt.text(i, v + total*0.01, f'{v}\\n({v/total*100:.1f}%)', \n",
    "                    ha='center', va='bottom')\n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "# =================================================================\n",
    "# 4. MODEL TRAINING AND EVALUATION\n",
    "# =================================================================\n",
    "\n",
    "class ModelTrainer:\n",
    "    \"\"\"Enhanced model training with MLflow integration\"\"\"\n",
    "    \n",
    "    def __init__(self, experiment_name: str):\n",
    "        self.experiment_name = experiment_name\n",
    "        self.models = {}\n",
    "        self.results = {}\n",
    "    \n",
    "    def prepare_data(self, X: pd.DataFrame, y: pd.Series, \n",
    "                    test_size: float = 0.2, balance_data: bool = True) -> Tuple:\n",
    "        \"\"\"Prepare training and test data with optional balancing\"\"\"\n",
    "        \n",
    "        # Split data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=test_size, random_state=RANDOM_STATE, stratify=y\n",
    "        )\n",
    "        \n",
    "        if balance_data:\n",
    "            logger.info(\"Applying SMOTE + Random Under Sampling for class balancing...\")\n",
    "            \n",
    "            # Apply SMOTE\n",
    "            smote = SMOTE(random_state=RANDOM_STATE)\n",
    "            X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "            \n",
    "            # Apply Random Under Sampling\n",
    "            rus = RandomUnderSampler(random_state=RANDOM_STATE)\n",
    "            X_train_balanced, y_train_balanced = rus.fit_resample(X_train_res, y_train_res)\n",
    "            \n",
    "            logger.info(f\"Original training set: {X_train.shape[0]} samples\")\n",
    "            logger.info(f\"Balanced training set: {X_train_balanced.shape[0]} samples\")\n",
    "            \n",
    "            return X_train_balanced, X_test, y_train_balanced, y_test\n",
    "        \n",
    "        return X_train, X_test, y_train, y_test\n",
    "    \n",
    "    def get_model_configs(self) -> List[Tuple]:\n",
    "        \"\"\"Get model configurations\"\"\"\n",
    "        return [\n",
    "            (LogisticRegression(max_iter=1000, class_weight='balanced', random_state=RANDOM_STATE), \n",
    "             'Logistic_Regression'),\n",
    "            (RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=RANDOM_STATE), \n",
    "             'Random_Forest'),\n",
    "            (XGBClassifier(eval_metric='logloss', scale_pos_weight=1, use_label_encoder=False, \n",
    "                          random_state=RANDOM_STATE), 'XGBoost'),\n",
    "            (LGBMClassifier(class_weight='balanced', random_state=RANDOM_STATE, verbose=-1), \n",
    "             'LightGBM'),\n",
    "            (CatBoostClassifier(verbose=0, random_state=RANDOM_STATE), \n",
    "             'CatBoost')\n",
    "        ]\n",
    "    \n",
    "    def evaluate_model(self, model, X_test: pd.DataFrame, y_test: pd.Series, \n",
    "                      model_name: str) -> Dict[str, float]:\n",
    "        \"\"\"Comprehensive model evaluation\"\"\"\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else y_pred\n",
    "        \n",
    "        metrics = {\n",
    "            'accuracy': accuracy_score(y_test, y_pred),\n",
    "            'roc_auc': roc_auc_score(y_test, y_pred_proba),\n",
    "            'f1_score': f1_score(y_test, y_pred),\n",
    "            'precision': classification_report(y_test, y_pred, output_dict=True)['1']['precision'],\n",
    "            'recall': classification_report(y_test, y_pred, output_dict=True)['1']['recall']\n",
    "        }\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    def plot_confusion_matrix(self, y_true, y_pred, model_name: str):\n",
    "        \"\"\"Plot confusion matrix\"\"\"\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        plt.figure(figsize=(6, 5))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                   xticklabels=['No', 'Yes'], yticklabels=['No', 'Yes'])\n",
    "        plt.title(f'Confusion Matrix: {model_name}')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.show()\n",
    "    \n",
    "    def cross_validate_model(self, model, X: pd.DataFrame, y: pd.Series, cv_folds: int = 5) -> Dict[str, float]:\n",
    "        \"\"\"Perform cross-validation\"\"\"\n",
    "        cv_scores = cross_val_score(model, X, y, cv=StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=RANDOM_STATE), \n",
    "                                   scoring='roc_auc')\n",
    "        \n",
    "        return {\n",
    "            'cv_mean': cv_scores.mean(),\n",
    "            'cv_std': cv_scores.std(),\n",
    "            'cv_scores': cv_scores.tolist()\n",
    "        }\n",
    "    \n",
    "    def train_all_models(self, X_train: pd.DataFrame, y_train: pd.Series, \n",
    "                        X_test: pd.DataFrame, y_test: pd.Series) -> Dict[str, Any]:\n",
    "        \"\"\"Train all models with MLflow tracking\"\"\"\n",
    "        \n",
    "        models_config = self.get_model_configs()\n",
    "        results = {}\n",
    "        \n",
    "        for model, model_name in models_config:\n",
    "            with mlflow.start_run(run_name=f\"{model_name}_run\") as run:\n",
    "                logger.info(f\"Training {model_name}...\")\n",
    "                start_time = time.time()\n",
    "                \n",
    "                # Enable auto-logging\n",
    "                if model_name == 'XGBoost':\n",
    "                    mlflow.xgboost.autolog()\n",
    "                elif model_name == 'LightGBM':\n",
    "                    mlflow.lightgbm.autolog()\n",
    "                elif model_name == 'CatBoost':\n",
    "                    mlflow.catboost.autolog()\n",
    "                else:\n",
    "                    mlflow.sklearn.autolog()\n",
    "                \n",
    "                # Train model\n",
    "                model.fit(X_train, y_train)\n",
    "                training_time = time.time() - start_time\n",
    "                \n",
    "                # Cross-validation\n",
    "                cv_results = self.cross_validate_model(model, X_train, y_train)\n",
    "                \n",
    "                # Evaluate on test set\n",
    "                test_metrics = self.evaluate_model(model, X_test, y_test, model_name)\n",
    "                \n",
    "                # Log custom parameters and metrics\n",
    "                mlflow.log_param(\"model_name\", model_name)\n",
    "                mlflow.log_param(\"training_time\", training_time)\n",
    "                mlflow.log_param(\"training_samples\", len(X_train))\n",
    "                mlflow.log_param(\"test_samples\", len(X_test))\n",
    "                \n",
    "                # Log cross-validation results\n",
    "                mlflow.log_metric(\"cv_roc_auc_mean\", cv_results['cv_mean'])\n",
    "                mlflow.log_metric(\"cv_roc_auc_std\", cv_results['cv_std'])\n",
    "                \n",
    "                # Log test metrics\n",
    "                for metric_name, metric_value in test_metrics.items():\n",
    "                    mlflow.log_metric(f\"test_{metric_name}\", metric_value)\n",
    "                \n",
    "                # Save model\n",
    "                model_path = f\"models/{model_name.lower()}_model\"\n",
    "                if model_name == 'XGBoost':\n",
    "                    mlflow.xgboost.log_model(model, model_path)\n",
    "                elif model_name == 'LightGBM':\n",
    "                    mlflow.lightgbm.log_model(model, model_path)\n",
    "                elif model_name == 'CatBoost':\n",
    "                    mlflow.catboost.log_model(model, model_path)\n",
    "                else:\n",
    "                    mlflow.sklearn.log_model(model, model_path)\n",
    "                \n",
    "                # Store results\n",
    "                results[model_name] = {\n",
    "                    'model': model,\n",
    "                    'test_metrics': test_metrics,\n",
    "                    'cv_results': cv_results,\n",
    "                    'training_time': training_time,\n",
    "                    'run_id': run.info.run_id\n",
    "                }\n",
    "                \n",
    "                # Print results\n",
    "                print(f\"\\n--- {model_name} Results ---\")\n",
    "                print(f\"Training Time: {training_time:.2f} seconds\")\n",
    "                print(f\"Cross-Validation ROC-AUC: {cv_results['cv_mean']:.4f} (±{cv_results['cv_std']:.4f})\")\n",
    "                print(f\"Test Accuracy: {test_metrics['accuracy']:.4f}\")\n",
    "                print(f\"Test ROC-AUC: {test_metrics['roc_auc']:.4f}\")\n",
    "                print(f\"Test F1-Score: {test_metrics['f1_score']:.4f}\")\n",
    "                \n",
    "                # Plot confusion matrix\n",
    "                y_pred = model.predict(X_test)\n",
    "                self.plot_confusion_matrix(y_test, y_pred, model_name)\n",
    "                \n",
    "                logger.info(f\"{model_name} training completed\")\n",
    "        \n",
    "        return results\n",
    "\n",
    "# =================================================================\n",
    "# 5. MAIN EXECUTION PIPELINE\n",
    "# =================================================================\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution pipeline\"\"\"\n",
    "    logger.info(\"Starting Insurance Cross-Sell Prediction Pipeline\")\n",
    "    \n",
    "    # Setup MLflow\n",
    "    experiment_id = setup_mlflow()\n",
    "    \n",
    "    # Load data\n",
    "    data_loader = DataLoader()\n",
    "    df = data_loader.load_data(Config.DATA_PATH)\n",
    "    \n",
    "    # Log dataset info to MLflow\n",
    "    with mlflow.start_run(run_name=\"data_exploration\") as run:\n",
    "        data_info = data_loader.basic_data_info(df)\n",
    "        mlflow.log_param(\"dataset_shape\", str(data_info['shape']))\n",
    "        mlflow.log_param(\"memory_usage_mb\", data_info['memory_usage_mb'])\n",
    "        mlflow.log_param(\"target_distribution\", str(data_info['target_distribution']))\n",
    "        \n",
    "        # Data exploration\n",
    "        explorer = DataExplorer()\n",
    "        explorer.plot_target_distribution(df)\n",
    "        explorer.plot_distributions(df)\n",
    "        explorer.plot_correlation_matrix(df)\n",
    "    \n",
    "    # Preprocessing\n",
    "    preprocessor = DataPreprocessor()\n",
    "    df_processed = preprocessor.fit_transform(df)\n",
    "    \n",
    "    # Prepare features and target\n",
    "    X = df_processed.drop(['Response', 'id'], axis=1, errors='ignore')\n",
    "    y = df_processed['Response']\n",
    "    \n",
    "    logger.info(f\"Feature matrix shape: {X.shape}\")\n",
    "    logger.info(f\"Target vector shape: {y.shape}\")\n",
    "    \n",
    "    # Model training\n",
    "    trainer = ModelTrainer(EXPERIMENT_NAME)\n",
    "    X_train, X_test, y_train, y_test = trainer.prepare_data(X, y, test_size=Config.TEST_SIZE)\n",
    "    \n",
    "    # Train all models\n",
    "    results = trainer.train_all_models(X_train, y_train, X_test, y_test)\n",
    "    \n",
    "    # Compare models\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"MODEL COMPARISON SUMMARY\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    comparison_df = pd.DataFrame({\n",
    "        model_name: {\n",
    "            'ROC-AUC': result['test_metrics']['roc_auc'],\n",
    "            'Accuracy': result['test_metrics']['accuracy'],\n",
    "            'F1-Score': result['test_metrics']['f1_score'],\n",
    "            'CV ROC-AUC': result['cv_results']['cv_mean'],\n",
    "            'Training Time (s)': result['training_time']\n",
    "        }\n",
    "        for model_name, result in results.items()\n",
    "    }).T\n",
    "    \n",
    "    print(comparison_df.round(4))\n",
    "    \n",
    "    # Best model\n",
    "    best_model_name = comparison_df['ROC-AUC'].idxmax()\n",
    "    best_model = results[best_model_name]['model']\n",
    "    \n",
    "    print(f\"\\nBest Model: {best_model_name}\")\n",
    "    print(f\"Best ROC-AUC Score: {comparison_df.loc[best_model_name, 'ROC-AUC']:.4f}\")\n",
    "    \n",
    "    # Log best model to MLflow\n",
    "    with mlflow.start_run(run_name=\"best_model_summary\") as run:\n",
    "        mlflow.log_param(\"best_model\", best_model_name)\n",
    "        mlflow.log_metric(\"best_roc_auc\", comparison_df.loc[best_model_name, 'ROC-AUC'])\n",
    "        mlflow.log_metric(\"best_accuracy\", comparison_df.loc[best_model_name, 'Accuracy'])\n",
    "        mlflow.log_metric(\"best_f1_score\", comparison_df.loc[best_model_name, 'F1-Score'])\n",
    "    \n",
    "    logger.info(\"Pipeline execution completed successfully!\")\n",
    "    \n",
    "    return results, preprocessor, best_model\n",
    "\n",
    "# =================================================================\n",
    "# 6. UTILITY FUNCTIONS\n",
    "# =================================================================\n",
    "\n",
    "def save_preprocessor(preprocessor: DataPreprocessor, filepath: str):\n",
    "    \"\"\"Save the preprocessor for future use\"\"\"\n",
    "    joblib.dump(preprocessor, filepath)\n",
    "    logger.info(f\"Preprocessor saved to {filepath}\")\n",
    "\n",
    "def load_preprocessor(filepath: str) -> DataPreprocessor:\n",
    "    \"\"\"Load a saved preprocessor\"\"\"\n",
    "    preprocessor = joblib.load(filepath)\n",
    "    logger.info(f\"Preprocessor loaded from {filepath}\")\n",
    "    return preprocessor\n",
    "\n",
    "def predict_new_data(model, preprocessor: DataPreprocessor, new_data: pd.DataFrame) -> np.ndarray:\n",
    "    \"\"\"Make predictions on new data\"\"\"\n",
    "    processed_data = preprocessor.transform(new_data)\n",
    "    predictions = model.predict(processed_data)\n",
    "    probabilities = model.predict_proba(processed_data)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "    \n",
    "    return predictions, probabilities\n",
    "\n",
    "# =================================================================\n",
    "# EXECUTION\n",
    "# =================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Create necessary directories\n",
    "    Path(\"models\").mkdir(exist_ok=True)\n",
    "    Path(\"data\").mkdir(exist_ok=True)\n",
    "    \n",
    "    # Run the main pipeline\n",
    "    results, preprocessor, best_model = main()\n",
    "    \n",
    "    # Save the preprocessor\n",
    "    save_preprocessor(preprocessor, \"models/preprocessor.joblib\")\n",
    "    \n",
    "    print(f\"\\nMLflow Tracking URI: {TRACKING_URI}\")\n",
    "    print(\"To view the MLflow UI, run: mlflow ui --backend-store-uri sqlite:///mlflow.db\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
